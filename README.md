# LLM_T5-small_CLI

## To run the CLI:

## [Step 1]
### Install the required dependancies and setup virtual environment:
```
$ python -m venv venv
$ ./venv/Scripts/activate
$ pip install -r requirements.txt
```
## [Step 2]
### Run the model:
```
$ python runthellm.py "[Your message]"
```

